/* generated by template _lsp.features.syntax_highlighting.LexerProvider*/

package de.monticore.lang.sdbasis._lsp.features.syntax_highlighting;

import de.monticore.lang.sdbasis._lsp.language_access.SDBasisLanguageAccess;
import de.monticore.lang.sdbasis._lsp.SDBasisLspAntlrParser;
import de.monticore.lang.sdbasis._parser.SDBasisAntlrLexer;
import de.mclsg.lsp.extensions.syntax_highlighting.lexer.LexerProvider;
import de.mclsg.lsp.extensions.syntax_highlighting.lexer.Token;
import de.mclsg.lsp.features.syntax_highlighting.HighlightLocalKeywordRule;
import de.mclsg.parser.MatchedToken;

import java.util.ArrayList;
import java.util.List;
import java.util.stream.Collectors;
import java.util.Collections;
import java.util.Comparator;

import org.slf4j.Logger;
import org.slf4j.LoggerFactory;

import de.mclsg.lsp.extensions.syntax_highlighting.lexer.AbstractLexerProvider;

public class SDBasisLexerProvider extends AbstractLexerProvider {
		private static final Logger logger = LoggerFactory.getLogger(SDBasisLexerProvider.class);
    protected final SDBasisLanguageAccess languageAccess;

    public SDBasisLexerProvider(SDBasisLanguageAccess languageAccess) {
        this.languageAccess = languageAccess;
				addLocalKeywordHighlighting();
    }

		protected void addLocalKeywordHighlighting(){
				addClassificationRule(new HighlightLocalKeywordRule());
		}

    @Override
    protected List<Token> getSimpleTokens(String input) {
    	// Use detailed parser => access to all tokens and position of them in the rules
    	SDBasisLspAntlrParser parser = languageAccess.getLspParser(input);
		parser.parse();

		List<Token> res = new ArrayList<>();
		List<MatchedToken> tokens = parser.getMatchedTokens();
		for(MatchedToken mt : tokens){
			Token t = mapToSingleToken(mt.token);
			t.setMatchedToken(mt);
			res.add(t);
		}

		// Use all available tokens from parser until the error(s), then fall back to lexer
		int maxPositionFromParser = res.stream().mapToInt(t -> t.getEndPosition()).max().orElse(0);
		if(maxPositionFromParser < input.length()) {
			SDBasisAntlrLexer lexer = this.languageAccess.getLexer(input);
			List<? extends org.antlr.v4.runtime.Token> antlrTokens = lexer.getAllTokens();
			List<Token> lexerRes = mapToTokens(antlrTokens);

			lexerRes.stream().filter(t -> t.getStartPosition() >= maxPositionFromParser).forEach(res::add);
		}

		res.addAll(parser.lexer.commentTokens);
		return res.stream().sorted(Comparator.comparing(Token::getStartPosition)).collect(Collectors.toList());
	}

    protected List<Token> mapToTokens(List<? extends org.antlr.v4.runtime.Token> antlrTokens) {
        return antlrTokens.stream()
            .map(this::mapToSingleToken)
            .collect(Collectors.toList());
    }

		protected Token mapToSingleToken(org.antlr.v4.runtime.Token antlrToken){
			return new Token(antlrToken.getStartIndex(), getTokenStopIndex(antlrToken), antlrToken.getType(), getTokenName(antlrToken.getType()));
		}

    protected String getTokenName(int tokenType) {
        return SDBasisAntlrLexer.VOCABULARY.getDisplayName(tokenType);
    }

    protected int getTokenStopIndex(org.antlr.v4.runtime.Token token) {
        return token.getStopIndex() + 1;
    }
}
